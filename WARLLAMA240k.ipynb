{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandra-udrescu/stuff/blob/main/WARLLAMA240k.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "JvMRbVLEJlZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec5a4289-be4b-4e3d-d49a-855616cb5c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gupload 1.1.0 requires click==7.0, but you have click 8.1.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m> \u001b[1mINFO    Installing latest transformers@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest transformers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest peft@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest peft\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest diffusers@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest diffusers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest trl@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest trl\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@title ðŸ¤— AutoTrain LLM\n",
        "#@markdown In order to use this colab\n",
        "#@markdown - upload train.csv to a folder named `data/`\n",
        "#@markdown - train.csv must contain a `text` column\n",
        "#@markdown - choose a project name if you wish\n",
        "#@markdown - change model if you wish, you can use most of the text-generation models from Hugging Face Hub\n",
        "#@markdown - add huggingface information (token and repo_id) if you wish to push trained model to huggingface hub\n",
        "#@markdown - update hyperparameters if you wish\n",
        "#@markdown - click `Runtime > Run all` or run each cell individually\n",
        "\n",
        "import os\n",
        "!pip install -U autotrain-advanced > install_logs.txt\n",
        "!autotrain setup > setup_logs.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/alexandra-udrescu/stuff/main/wh40k.txt -O"
      ],
      "metadata": {
        "id": "86G6G5fGlxSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8155787-5d9a-40fb-8831-7328d25acf1e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 64.6M  100 64.6M    0     0  91.9M      0 --:--:-- --:--:-- --:--:-- 91.8M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('wh40k.txt', 'r') as f:\n",
        "    text_data = f.readlines()\n",
        "\n",
        "clean = []\n",
        "\n",
        "for line in text_data:\n",
        "  if \"pp.\" not in line and \"pg.\" not in line and len(line.split(' ')) >= 4:\n",
        "    clean.append(line.strip())\n",
        "\n",
        "print(clean[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTisv0NCm07M",
        "outputId": "8d78aeea-ba71-4ed3-862d-83cfe13d8d4b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"The Cadian Sector of the Milky Way Galaxy is a sector of the Imperium of Man in the Segmentum Obscurus to the galactic north of Terra. The planet Cadia is the Imperium of Man's most important Fortress World as designated by the Administratum. It guards the only known navigable route, a passage called the Cadian Gate, to and from the massive Warp rift known as the Eye of Terror. The world's dangerous proximity to the Eye of Terror has made it necessary for the people of Cadia to heavily fortify the planet. The Cadian Sector is always the first target of the Chaos Warmaster Abaddon the Despoiler's assaults and multiple Black Crusades, when the Forces of Chaos launch themselves from the Eye of Terror every few centuries in an attempt to break out and invade the Imperium proper as they did during the Horus Heresy.\", \"Some 40 standard years before the outbreak of the Horus Heresy, Cadia was a world inhabited by a primitive race of violet-eyed humans who worshipped the four Chaos Gods, probably a remnant of Mankind that had turned to the Ruinous Powers during the hardships of the Age of Strife. Prompted by the so-called Pilgrimage of the Primarch Lorgar of the Word Bearers Legion to discover whether or not the Gods once worshipped by adherents of the Old Faith of the Word Bearers' homeworld of Colchis actually existed, Lorgar journeyed with his Word Bearers Legion's Chapter of the Serrated Sun to what was then the fringes of known Imperial space as part of the 1301st Expeditionary Fleet of the Great Crusade. At this time, Lorgar had not yet fallen to Chaos, though he had turned against the Emperor of Mankind as a deity no longer worthy of his worship after the Emperor and the Ultramarines Legion had personally humiliated him and the entire Word Bearers Legion on the world of Khur, 43 standard years before the start of the Horus Heresy.\", \"The Emperor had come to Khur personally with Malcador the Sigillite after ordering the Ultramarines to destroy the Khurian city of Monarchia where the Emperor was worshipped as a God as a result of the teachings of the Word Bearers. He made his displeasure known to Lorgar about the Word Bearers spreading the religion of Emperor-worship to every world they brought into the Imperium, in direct contravention of the rationalist, atheist philosophy of the Imperial Truth. The Emperor forced the entire Legion to kneel against their will through the use of his psychic might and then explained that they were the only Astartes Legion to have failed his purpose on the Great Crusade. After this humiliation Lorgar, on the advice of his First Captain Kor Phaeron and the Word Bearers First Chaplain Erebus, decided to undertake a Pilgrimage to discover if the Gods worshipped by the ancient Old Faith of Colchis were real and worthy of the Word Bearers' faith and allegiance, since clearly the Emperor was not.\", 'The Word Bearers were also accompanied on this Pilgrimage by 5 members of the Adeptus Custodes who had been set by the Emperor to watch over everything the Word Bearers did to prevent them from falling back into error once more. The 1301st Expeditionary Fleet exited the Warp near the largest Warp Storm in the universe, later known as the Eye of Terror. The Fleet\\'s Master of Astropaths advised Lorgar that unusual \"voices\" in the Warp were heard in the vicinity of the great Warp rift, voices that spoke directly to the Primarch as well, the voices of the Chaos entities within the Immaterium.', 'The decision was made to hold orbit over Cadia and for the 1301st Fleet\\'s elements to make planetfall on the unknown world, designated as 1301-12. The landing force was comprised of Imperial Army, Word Bearers, Adeptus Custodes and Legiones Cybernetica elements. The landing party, led by Lorgar, was greeted by a large number of barbaric human tribes, people described as \"dressed in rags and wielding spears tipped by flint blades...yet they showed little fear.\" Most notable were the barbarians\\' purple eyes, which reflected the colour of the Eye of Terror itself in the spectrum of visible light. Despite the Custodian Vendatha\\'s protests and request to execute the heathens, the Word Bearers approached the natives. A woman emerged from the crowd and addressed the Primarch directly, calling him Lorgar Aurelian and welcoming him to Cadia. This woman, the priestess Ingethel, would ultimately lead the Primarch down a path of spiritual enlightenment that actually marked the beginning of Lorgar\\'s fall to heresy and Chaos. Later, Ingethel of Cadia would lead the 1301st Fleet\\'s scout vessel \"Orfeo\\'s Lament\" into the Eye of Terror and thus change the Word Bearers forever as they were exposed to the Ruinous Powers of Chaos and slowly corrupted, the first of the Legiones Astartes to worship the Chaos Gods and become Traitors to the Emperor. The Cadians, primitive as they were, used a language which was akin to the Word Bearers\\' own Colchisan tongue. Many traditions of the Word Bearers were mirrored by the culture of ancient Cadia, leading Lorgar to believe that the original settlers of both his own homeworld of Colchis and Cadia shared a common heritage. Following the visits into the Eye of Terror, Lorgar ordered a cyclonic bombardment of the planet, wiping out the Cadians and leaving the planet abandoned so none would know what had transpired.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(clean))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCASHkL3nx1v",
        "outputId": "125ea1b6-4b60-4f99-973d-b91f760eb6de"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "181675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir data"
      ],
      "metadata": {
        "id": "7TMjdVwTn3PM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc4d525-5cb5-457f-a808-94c0d9943c52"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory â€˜dataâ€™: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "csv_filename = \"data/train.csv\"\n",
        "with open(csv_filename, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"text\"])\n",
        "    for text in clean:\n",
        "        writer.writerow([text])"
      ],
      "metadata": {
        "id": "30AjSIZgn0D2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! huggingface-cli login"
      ],
      "metadata": {
        "id": "roimayOzqU2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ad5834-e218-45b3-ba6f-45255daca65d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "A2-_lkBS1WKA"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "#@markdown Note: if you are using a restricted/private model, you need to enter your Hugging Face token in the next step.\n",
        "project_name = 'llama_wh40k_2' # @param {type:\"string\"}\n",
        "model_name = 'meta-llama/Llama-2-7b-chat-hf' # @param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "repo_id = \"username/repo_name\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 2e-4 # @param {type:\"number\"}\n",
        "num_epochs = 1 #@param {type:\"number\"}\n",
        "batch_size = 8 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "block_size = 256 # @param {type:\"number\"}\n",
        "trainer = \"sft\" # @param [\"default\", \"sft\"] {type:\"raw\"}\n",
        "warmup_ratio = 0.1 # @param {type:\"number\"}\n",
        "weight_decay = 0.01 # @param {type:\"number\"}\n",
        "gradient_accumulation = 4 # @param {type:\"number\"}\n",
        "use_fp16 = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_peft = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_int4 = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "lora_r = 16 #@param {type:\"number\"}\n",
        "lora_alpha = 32 #@param {type:\"number\"}\n",
        "lora_dropout = 0.05 #@param {type:\"number\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"REPO_ID\"] = repo_id\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_EPOCHS\"] = str(num_epochs)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"BLOCK_SIZE\"] = str(block_size)\n",
        "os.environ[\"WARMUP_RATIO\"] = str(warmup_ratio)\n",
        "os.environ[\"WEIGHT_DECAY\"] = str(weight_decay)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"USE_FP16\"] = str(use_fp16)\n",
        "os.environ[\"USE_PEFT\"] = str(use_peft)\n",
        "os.environ[\"USE_INT4\"] = str(use_int4)\n",
        "os.environ[\"LORA_R\"] = str(lora_r)\n",
        "os.environ[\"LORA_ALPHA\"] = str(lora_alpha)\n",
        "os.environ[\"LORA_DROPOUT\"] = str(lora_dropout)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "id": "g3cd_ED_yXXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bee5211-21bb-4a1d-f707-2ae7e4db92fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Running LLM\u001b[0m\n",
            "> \u001b[1mINFO    Params: Namespace(version=False, train=True, deploy=False, inference=False, data_path='data/', train_split='train', valid_split=None, text_column='text', model='meta-llama/Llama-2-7b-chat-hf', learning_rate=0.0002, num_train_epochs=1, train_batch_size=8, warmup_ratio=0.1, gradient_accumulation_steps=4, optimizer='adamw_torch', scheduler='linear', weight_decay=0.01, max_grad_norm=1.0, seed=42, add_eos_token=False, block_size=256, use_peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, project_name='llama_wh40k_2', evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, fp16=False, push_to_hub=False, use_int8=False, model_max_length=1024, repo_id=None, use_int4=True, trainer='default', target_modules=None, merge_adapter=False, token=None, backend='default', username=None, use_flash_attention_2=False, func=<function run_llm_command_factory at 0x7d96b78fb370>)\u001b[0m\n",
            "> \u001b[1mINFO    loading dataset from csv\u001b[0m\n",
            "Using pad_token, but it is not set yet.\n",
            "Loading checkpoint shards: 100% 2/2 [00:58<00:00, 29.35s/it]\n",
            "Running tokenizer on train dataset:   4% 7000/181675 [00:00<00:14, 11920.76 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Running tokenizer on train dataset: 100% 181675/181675 [00:15<00:00, 11967.70 examples/s]\n",
            "Grouping texts in chunks of 256 (num_proc=4): 100% 181675/181675 [00:06<00:00, 27321.49 examples/s]\n",
            "> \u001b[1mINFO    creating trainer\u001b[0m\n",
            "{'loss': 2.3527, 'learning_rate': 4.4444444444444447e-05, 'epoch': 0.8}\n",
            "{'train_runtime': 15298.864, 'train_samples_per_second': 4.268, 'train_steps_per_second': 0.133, 'train_loss': 2.334506764131434, 'epoch': 1.0}\n",
            "100% 2040/2040 [4:14:58<00:00,  7.50s/it]\n",
            "> \u001b[1mINFO    Finished training, saving model...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!autotrain llm \\\n",
        "--train \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--data-path data/ \\\n",
        "--text-column text \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--epochs ${NUM_EPOCHS} \\\n",
        "--block-size ${BLOCK_SIZE} \\\n",
        "--warmup-ratio ${WARMUP_RATIO} \\\n",
        "--lora-r ${LORA_R} \\\n",
        "--lora-alpha ${LORA_ALPHA} \\\n",
        "--lora-dropout ${LORA_DROPOUT} \\\n",
        "--weight-decay ${WEIGHT_DECAY} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "$( [[ \"$USE_FP16\" == \"True\" ]] && echo \"--fp16\" ) \\\n",
        "$( [[ \"$USE_PEFT\" == \"True\" ]] && echo \"--use-peft\" ) \\\n",
        "$( [[ \"$USE_INT4\" == \"True\" ]] && echo \"--use-int4\" ) \\\n",
        "# $( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN} --repo-id ${REPO_ID}\" ) \\\n",
        "--merge-adapter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"./llama_wh40k_2\")"
      ],
      "metadata": {
        "id": "vkqsoZ_G5gq8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d14f6e23803440a8a54bc1563e85c72c",
            "bef42c3eee8842feb1cbab3c5d66fcc8",
            "2699a2a2fa7c4b4799b843e003a10689",
            "24fac751d6ee4aa8aefa1b37fddbd9bf",
            "217c2dc5776a42cb81d5b7033b7f2d4b",
            "232142ea21b846a690a6d038b66831fb",
            "e4fb2d705e0441b7a45c98c083d26237",
            "2cbf6270ba9a469da05bf00417276e60",
            "a56b40e68f364319a9047c5aa8ca3fd6",
            "cdbb664f5af44ea5a61120eca6ad3e4d",
            "fad7a12590064d89981c70a285cc4556"
          ]
        },
        "outputId": "60d56bda-76ca-49ba-d23e-eacca43e3643"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d14f6e23803440a8a54bc1563e85c72c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./llama_wh40k_2/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cHmQqjpEYdl",
        "outputId": "31c7bb3a-439b-486d-b03f-06bbf348cd86"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"Belisarius Cawl is hated by many members of Adeptus Mechanicus because \", return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "ood-pj4uFB8r"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rez = model.generate(inputs, do_sample=True, max_length=100)"
      ],
      "metadata": {
        "id": "ITzRWXtbDcJm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_output = tokenizer.decode(rez[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "FpjO-Ui__TJk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW_liPsVJ3H3",
        "outputId": "c531497d-3f8e-4aee-96c3-38334f955133"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Belisarius Cawl is hated by many members of Adeptus Mechanicus because  of his unorthodox methods, which are not bound by the rigid adherence to the \"Codex Astartes\" that most of the Tech-priests of the Adeptus Mechanicus hold so dear. He is also hated because of his lack of respect for the traditional roles of the Adeptus Mechanicus, and because he doesÃ¡n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhuDmKkaJgl-",
        "outputId": "af5f6b43-9acc-4ab3-cec4-dc74a59e9378"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r . /content/gdrive/MyDrive/stuffy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sphklO-2J0gt",
        "outputId": "6c22bb10-f7a1-4bd4-d2ec-37d14c7b493d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot open './gdrive/MyDrive/Uni/UniHW/Y4/IOC/Usability Matrix.gsheet' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/UniHW/Y4/IOC/IOC Text.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/UniHW/Y4/MPS/MPS Project Sprint 2 Retro.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/UniHW/Y4/MPS/MPS Project Sprint 3 Retro.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/UniHW/Y4/MPS/MPS Development Report.gsheet' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/UniHW/Y4/MPS/Sprint 5 MPS Project Retro.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/UniHW/Y4/MP/MP - Line chart 1.gsheet' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/UniHW/Y4/MP/MP.gslides' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/UniHW/Y4/Licenta/Licenta References.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/UniHW/Y4/Licenta/pics/Components.gdraw' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/AA/Labs/2022-2023/docs/Lab 4 Reduceri Turing 2.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/AA/Labs/2022-2023/docs/Lab 5 Notatii Asimptotice.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/AA/Labs/2022-2023/docs/Lab 2 - Turing Machines.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/AA/Labs/2022-2023/docs/Lab 7 Algoritmi Nedeterministi.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/AA/Labs/2022-2023/docs/Lab 11 TDA.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/AA/Labs/2022-2023/docs/Lab 3 Reduceri Turing.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/AA/Labs/2023-2024/Labs_OLD/Copy of Lab 2 - Turing Machines.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/AA/Labs/2023-2024/Labs_OLD/Copy of Lab 3 Reduceri Turing.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/AA/Labs/2023-2024/Labs_OLD/Copy of Lab 4 Reduceri Turing 2.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/AA/Labs/2023-2024/Labs_OLD/Copy of Lab 5 Notatii Asimptotice.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/AA/Labs/2023-2024/Labs_OLD/Copy of Lab 7 Algoritmi Nedeterministi.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/AA/Labs/2023-2024/Labs_OLD/Copy of Lab 11 TDA.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/LFA/LFA.Alexandra Udrescu.Exercise sheet 1.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/LFA/2022-2023/Prezenta LFA.gsheet' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/LFA/LFA 2023-2024/CATALOG LFA CB 2023-2024 .gsheet' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/Notite/CPL/Curs 3 TODO.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/Notite/CPL/Curs 4.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/Notite/CPL/Curs 5.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/Notite/CPL/Curs 6.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/Notite/CPL/Curs 7.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/Notite/CPL/Curs 13.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/Notite/CPL/Curs 8.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/Notite/CPL/Curs 12.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/Notite/CPL/Curs 9.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/Notite/CPL/Curs 11.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/Notite/CPL/Curs 10 TODO.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/PM/Untitled document.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/PM/PM feedback anonim live.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/PP/2023/Code review/Lab3.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/PP/2023/PP-2023-CatalogCD.gsheet' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/PP/2022/PP - prezenta.gsheet' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Uni/Administrativ/Ibanuri.gsheet' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/My OCs/Harry Potter World/Vincent.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/My OCs/Harry Potter World/Gilbert.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/My OCs/Harry Potter World/Nysseno.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/My OCs/Harry Potter World/Nerumi.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/My OCs/Harry Potter World/Students/Medea Rosethorn.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/My OCs/Harry Potter World/Students/Violet.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/My OCs/Harry Potter World/Students/Kasiya.gdoc' for reading: Operation not supported\n",
            "cp: cannot open \"./gdrive/MyDrive/My OCs/Harry Potter World/Vince's Friend.gdoc\" for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/My OCs/Harry Potter World/Scanned_20220507-1101.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/My OCs/Other fandoms OCs/Moriarty the Patriot/Dominique.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/My OCs/WhatsApp Chat with GrupuletðŸ˜ŽðŸ¥´.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/My OCs/templates/template1.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/My OCs/templates/template2.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Copy of ChatGPT code review evaluation.gdoc' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Materii.gsheet' for reading: Operation not supported\n",
            "cp: cannot open './gdrive/MyDrive/Abstract oist.gdoc' for reading: Operation not supported\n",
            "cp: cannot copy a directory, '.', into itself, '/content/gdrive/MyDrive/stuffy/.'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d14f6e23803440a8a54bc1563e85c72c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bef42c3eee8842feb1cbab3c5d66fcc8",
              "IPY_MODEL_2699a2a2fa7c4b4799b843e003a10689",
              "IPY_MODEL_24fac751d6ee4aa8aefa1b37fddbd9bf"
            ],
            "layout": "IPY_MODEL_217c2dc5776a42cb81d5b7033b7f2d4b"
          }
        },
        "bef42c3eee8842feb1cbab3c5d66fcc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_232142ea21b846a690a6d038b66831fb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e4fb2d705e0441b7a45c98c083d26237",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2699a2a2fa7c4b4799b843e003a10689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cbf6270ba9a469da05bf00417276e60",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a56b40e68f364319a9047c5aa8ca3fd6",
            "value": 2
          }
        },
        "24fac751d6ee4aa8aefa1b37fddbd9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdbb664f5af44ea5a61120eca6ad3e4d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fad7a12590064d89981c70a285cc4556",
            "value": " 2/2 [00:45&lt;00:00, 20.68s/it]"
          }
        },
        "217c2dc5776a42cb81d5b7033b7f2d4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "232142ea21b846a690a6d038b66831fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4fb2d705e0441b7a45c98c083d26237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cbf6270ba9a469da05bf00417276e60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a56b40e68f364319a9047c5aa8ca3fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdbb664f5af44ea5a61120eca6ad3e4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad7a12590064d89981c70a285cc4556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}